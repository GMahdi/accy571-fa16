{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a98c739c45025e75b7a8a39168517825",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "bc4a7fcc20e6da19863d121f8f2b3331",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 2. Nearest Neighbors.\n",
    "\n",
    "In this problem, we fit a $k$-nearest neighbors (kNN) model that takes the day of the week and depature delays as input and predicts whether a flight is on time or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "58973895232ca19b67781463fe901378",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_is_instance, assert_equal, assert_almost_equal\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal\n",
    "from pandas.util.testing import assert_index_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d83118cd03cf56b1524ddc4785042cfd",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We use the same [airline on-time performance data](http://stat-computing.org/dataexpo/2009/) from the lessons. You can find the descriptions [here](http://stat-computing.org/dataexpo/2009/). We use 4 columns: `DayOfWeek`, `ArrDelay` `DepDelay`, and `Origin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "27c6d793725982583f90c23787cc463c",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "filename = \"/home/data_scientist/data/2001.csv\"\n",
    "usecols = (3, 14, 15, 17)\n",
    "names = [\"DayOfWeek\", \"ArrDelay\", \"DepDelay\", \"Origin\"]\n",
    "\n",
    "all_data = pd.read_csv(filename, header=0, na_values=[\"NA\"], usecols=usecols, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a473fee8b78103cf6541ac0e6979be87",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We perform some data pre-processing, similarly to the [Introduction to Logistic Regression](https://github.com/UI-DataScience/accy571-fa16/blob/master/Week6/notebooks/intro2lr.ipynb) notebook.\n",
    "\n",
    "To simplify the computations, we first extract only those flights that depart from Willard airport (CMI). After this, we drop all rows that have missing values (\"`NA`\") in any of the columns.\n",
    "\n",
    "We next create a categorical column, _arrival late_, that is zero if the flight arrived less than 5 minutes after the scheduled arrival time, or one if it arrived more than this number of minutes after the scheduled time. We will use this\n",
    "to train our logistic regressor.\n",
    "\n",
    "Furthermore, to save memory, we drop the columns that we no longer need: the origin airport and arrival delay columns.\n",
    "\n",
    "Finally, we use reset the indices so that the first row corresponds to index 0, the second row to index 1, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "96ebf139f599b06fe159f020862a101a",
     "grade": false,
     "grade_id": "local",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local = all_data[all_data[\"Origin\"] == \"CMI\"].dropna()\n",
    "\n",
    "local[\"ArrLate\"] = (local[\"ArrDelay\"] > 5).astype(int)\n",
    "\n",
    "local = local.drop([\"Origin\", \"ArrDelay\"], axis=1)\n",
    "\n",
    "local = local.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f9e425b5e0eaa60811b7a3e6fc314d9b",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's print out the first 10 columns of the resulting data frame.\n",
    "\n",
    "```python\n",
    ">>> print(local.head(10))\n",
    "```\n",
    "```\n",
    "   DayOfWeek  DepDelay  ArrLate\n",
    "0          1      15.0        1\n",
    "1          2      -5.0        1\n",
    "2          3      52.0        1\n",
    "3          4      12.0        0\n",
    "4          5       0.0        0\n",
    "5          7     152.0        1\n",
    "6          1      51.0        1\n",
    "7          2       3.0        0\n",
    "8          3      -7.0        0\n",
    "9          4      14.0        0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "10bc0bf383d16b5dfb942bbf5539daa3",
     "grade": false,
     "grade_id": "print_local",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "31b762be02fece8fba7141ed1c2c5816",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To evaluate how well our regressor will perform on new, unseen data, we want to train on a subset of the data and test this new regressor on unseen _test_ data. So, we split our data into a _training_ sample, and a testing sample by using the `train_test_split` method in scikit learn. Specifically, in this example, we use 75% of the data for training and 25% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b8a8a0795f72ae2b11b2c2553e9ac787",
     "grade": false,
     "grade_id": "train_test_split",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model by splitting into train and test sets\n",
    "X = local.drop(\"ArrLate\", axis=1)\n",
    "y = np.ravel(local[\"ArrLate\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d185a0c09fb70377c8f1ba0b8053a2e3",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note that the six columns we want to use for training have different scales: `DayOfWeek` ranges from 1 to 7, while `DepDelay` ranges from -19 to 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1f0e819118f98c904a2aea0fbf5869f8",
     "grade": false,
     "grade_id": "print_min",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "41292b700538418d5c2b594abe2c6df0",
     "grade": false,
     "grade_id": "print_max",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "22339891454489ffe9ba616e2a2fee4e",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Before we apply the machine learning technique, we need to standardize the features. Otherwise, a feature with a big scale will dominate another feature with a smaller scale when the kNN algorithm considers the distance between the neighbors. One way to standardize the features is to rescale the range of features to $[0, 1]$:\n",
    "\n",
    "$$x' = \\frac{x - \\text{min}(x)}{\\text{max}(x)-\\text{min}(x)}$$\n",
    "\n",
    "where $x$ is an original value, $x'$ is the normalized value. `normalize()` in the following code cell takes a data frame and returns a data frame with all columns rescaled to the range $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0c9e6e78410f94949c4dd25054a8d475",
     "grade": false,
     "grade_id": "normalize_define",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \n",
    "    result = df.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7fa781bb93bbc5776efe391daeb06c97",
     "grade": false,
     "grade_id": "normalize_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_normalized = normalize(X_train)\n",
    "X_test_normalized = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "615897a9f7ed01dad4a685ac2a1cb973",
     "grade": false,
     "grade_id": "print_normalized_min",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_normalized.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "71c54f4137fa2ede2534b36f69aab2c1",
     "grade": false,
     "grade_id": "print_normalized_max",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(X_train_normalized.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6285d6adb5e0c59066e47923765ac534",
     "grade": false,
     "grade_id": "markdown_7",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Train a k-Nearest Neighbors model\n",
    "\n",
    "Now that we have standardized the test sets, we are finally ready to apply the $k$-Nearest Neighbors algorithm.\n",
    "\n",
    "- Write a function named `fit_knn_and_predict()` that fits a $k$-Nearest Neighbors using [KNeighborsClassifier()](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) in scikit learn.\n",
    "- Note that the function takes 4 arguments, but it is not necessary that you use all 4 arguments in the function. You should decide which arguments are needed and which are not.\n",
    "- If you read the [sklearn.neighbors.KNeighborClassifer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) carefully, there are many optional parameters that you can use in `KNeighborClassifer()`, e.g., `n_neighbors`, `weights`, etc. Use defaults values for all optional parameters. That is, do not use any optional paramters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e52108232461e3b8e56ee01c63df8fff",
     "grade": false,
     "grade_id": "fit_knn_and_predict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_knn_and_predict(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits a kNN classifer on the training data.\n",
    "    Returns the predicted values on the test data.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    X_train: A pandas data frame. The features of the training set.\n",
    "    X_test: A pandas data frame. The features of the test set.\n",
    "    y_train: A numpy array. The labels of the training set.\n",
    "    y_test: A numpy array. The labels of the test set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 1-D numpy array. \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a140dbda97105486f4a070bdc57bf8d4",
     "grade": false,
     "grade_id": "fit_knn_and_predict_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = fit_knn_and_predict(X_train_normalized, X_test_normalized, y_train, y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy = {0:3.1f} %\".format(100.0 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d6770f687ed293ae8340953fa13e6c2a",
     "grade": true,
     "grade_id": "fit_knn_and_predict_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(y_pred, np.ndarray)\n",
    "assert_equal(len(y_pred), len(y_test))\n",
    "assert_array_equal(\n",
    "    np.where(y_pred != y_test)[0],\n",
    "    [  6,  12,  24,  25,  26,  27,  29,  31,  35,  37,  38,  39,  41,\n",
    "        46,  48,  61,  62,  64,  83,  86,  93,  99, 101, 108, 110, 114,\n",
    "       117, 128, 142, 143, 159, 162, 167, 168, 170, 172, 181, 185, 189,\n",
    "       194, 196, 207, 208, 213, 219, 221, 229, 233, 236, 237, 239, 240,\n",
    "       242, 246, 247, 250, 251, 252, 254, 271, 280, 297, 304, 312, 317,\n",
    "       319, 322, 344, 345, 349, 362, 376, 383, 387, 392, 400, 405, 409,\n",
    "       412, 415, 417]\n",
    ")\n",
    "assert_almost_equal(accuracy, 0.80896226415094341)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
