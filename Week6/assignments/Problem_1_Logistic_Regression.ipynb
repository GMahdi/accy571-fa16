{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a98c739c45025e75b7a8a39168517825",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "dd95e023bd0b823c0463799472cfd2bf",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 1. Logistic Regression.\n",
    "\n",
    "In this problem, we fit a logistic regression model that takes the day of the week and depature delays as input, and predicts whether a flight is on time or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7735dcc575cfb0c3c4c6ef3b368f5ecc",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_is_instance, assert_equal, assert_almost_equal\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal\n",
    "from pandas.util.testing import assert_index_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "97a21aa88bd86699b379b74bf9cd51e6",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We use the same [airline on-time performance data](http://stat-computing.org/dataexpo/2009/) from the lessons. You can find the descriptions [here](http://stat-computing.org/dataexpo/2009/) and [here](http://stat-computing.org/dataexpo/2009/the-data.html). We use four columns: `DayOfWeek`, `ArrDelay`, `DepDelay`, and `Origin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "27c6d793725982583f90c23787cc463c",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "filename = \"/home/data_scientist/data/2001.csv\"\n",
    "usecols = (3, 14, 15, 17)\n",
    "names = [\"DayOfWeek\", \"ArrDelay\", \"DepDelay\", \"Origin\"]\n",
    "\n",
    "all_data = pd.read_csv(filename, header=0, na_values=[\"NA\"], usecols=usecols, names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6e9045ae26e91956f44ed5d4b6805483",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We perform some data pre-processing, similarly to the [Introduction to Logistic Regression](https://github.com/UI-DataScience/accy571-fa16/blob/master/Week6/notebooks/intro2lr.ipynb) notebook.\n",
    "\n",
    "To simplify the computations, we first extract only those flights that depart from Willard Airport (CMI). After this, we drop all rows that have missing values (\"`NA`\") in any of the columns.\n",
    "\n",
    "We next create a categorical column, `ArrLate` (_arrival late_), that is zero if the flight arrived less than or equal to 5 minutes after the scheduled arrival time, or one if it arrived more than 5 minutes after the scheduled time. We will use this column as the target label to train our logistic regressor.\n",
    "\n",
    "Furthermore, to save memory, we drop the columns that we no longer need: the origin airport and the arrival delay.\n",
    "\n",
    "Finally, we reset the indices so that the first row corresponds to index 0, the second row to index 1, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "96ebf139f599b06fe159f020862a101a",
     "grade": false,
     "grade_id": "local",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local = all_data[all_data[\"Origin\"] == \"CMI\"].dropna()\n",
    "\n",
    "local[\"ArrLate\"] = (local[\"ArrDelay\"] > 5).astype(int)\n",
    "\n",
    "local = local.drop([\"Origin\", \"ArrDelay\"], axis=1)\n",
    "\n",
    "local = local.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8b3e9f5a7ca8359aa96e822efae074d6",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Let's print the first 10 columns of the resulting data frame, and check what it looks like.\n",
    "\n",
    "```python\n",
    ">>> print(local.head(10))\n",
    "```\n",
    "```\n",
    "   DayOfWeek  DepDelay  ArrLate\n",
    "0          1      15.0        1\n",
    "1          2      -5.0        1\n",
    "2          3      52.0        1\n",
    "3          4      12.0        0\n",
    "4          5       0.0        0\n",
    "5          7     152.0        1\n",
    "6          1      51.0        1\n",
    "7          2       3.0        0\n",
    "8          3      -7.0        0\n",
    "9          4      14.0        0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "10bc0bf383d16b5dfb942bbf5539daa3",
     "grade": false,
     "grade_id": "print_local",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(local.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ba3325234e147520f1a5ecf6ef0c5797",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Split the data frame and convert to category variables\n",
    "\n",
    "We will use the scikit learn library to perform logistic regression on `DepDelay` and `DayOfWeek` to predict `ArrLate`. To fit a logistic regression model, we need to convert `DayOfWeek` into categorical variables. Thus, in the following code cell,\n",
    "\n",
    "- Use the formula interface to construct `X` (a `pandas` DataFrame) and `y` (a numpy array) for use in `sklearn`.\n",
    "- Use the `dmatrics()` function in the `patsy` library, which supports a formula interface (as we used with the `statsmodel` library).\n",
    "- Turn `DayOfWeek` into a category variable (by wrapping them in the `C()` notation). Do _not_ turn the `DepDelay` column into a category variable.\n",
    "- The return value `y` needs to be a one-dimensional array for scikit learn. (Note: this part of the code is already provided for you.)\n",
    "- If you are not sure how to do this, there is an example in the [Introduction to Logistic Regression](https://github.com/UI-DataScience/accy571-fa16/blob/master/Week6/notebooks/intro2lr.ipynb) notebook.\n",
    "\n",
    "In the end, we should have\n",
    "\n",
    "```python\n",
    ">>> X, y = convert_df_using_patsy_formula(local)\n",
    ">>> print(X.head())\n",
    "```\n",
    "```\n",
    "   Intercept  C(DayOfWeek)[T.2]  C(DayOfWeek)[T.3]  C(DayOfWeek)[T.4]  \\\n",
    "0        1.0                0.0                0.0                0.0   \n",
    "1        1.0                1.0                0.0                0.0   \n",
    "2        1.0                0.0                1.0                0.0   \n",
    "3        1.0                0.0                0.0                1.0   \n",
    "4        1.0                0.0                0.0                0.0   \n",
    "\n",
    "   C(DayOfWeek)[T.5]  C(DayOfWeek)[T.6]  C(DayOfWeek)[T.7]  DepDelay  \n",
    "0                0.0                0.0                0.0      15.0  \n",
    "1                0.0                0.0                0.0      -5.0  \n",
    "2                0.0                0.0                0.0      52.0  \n",
    "3                0.0                0.0                0.0      12.0  \n",
    "4                1.0                0.0                0.0       0.0  \n",
    "```\n",
    "```python\n",
    ">>> print(y)\n",
    "```\n",
    "```\n",
    "[1 1 1 ..., 1 0 1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7310c7ab538b307b20bfd4a7a0e76bd4",
     "grade": false,
     "grade_id": "convert_df_using_patsy_formula_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_df_using_patsy_formula(df):\n",
    "    \"\"\"\n",
    "    Uses patsy formula interface to \n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    df: A pandas data frame with columns:\n",
    "        \"DayOfWeek\", \"DepDelay\", and \"ArrLate\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X: A pandas data frame with columns:\n",
    "       \"DepDelay\", \"Intercept\", \"C(DayOfWeek)[T.2]\",\n",
    "       \"C(DayOfWeek)[T.3]\", \"C(DayOfWeek)[T.4]\",\n",
    "       \"C(DayOfWeek)[T.5]\", and \"C(DayOfWeek)[T.6]\"\n",
    "    y: A 1-D numpy array. Same as the \"ArrLate\" column of \"df\".\n",
    "    \"\"\"\n",
    "    \n",
    "    y, X = dmatrices(\n",
    "    # YOUR CODE HERE\n",
    "    )\n",
    "    # y needs to be a 1D array for scikit learn\n",
    "    y = np.ravel(y).astype(np.int)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c19c37fb20de3738481cac18c34fb20e",
     "grade": false,
     "grade_id": "convert_df_using_patsy_formula_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X, y = convert_df_using_patsy_formula(local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "edda6918eb42eba7bba5c1bbdf4cedd8",
     "grade": false,
     "grade_id": "print_X_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a277c6d47df12f3a336dbcd1012b15a0",
     "grade": true,
     "grade_id": "convert_df_using_patsy_formula_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(X, pd.DataFrame)\n",
    "assert_is_instance(y, np.ndarray)\n",
    "\n",
    "assert_equal(len(local), len(X))\n",
    "assert_equal(len(local), len(y))\n",
    "\n",
    "columns = [\n",
    "    'C(DayOfWeek)[T.2]', 'C(DayOfWeek)[T.3]', 'C(DayOfWeek)[T.4]',\n",
    "    'C(DayOfWeek)[T.5]', 'C(DayOfWeek)[T.6]', 'C(DayOfWeek)[T.7]',\n",
    "    'DepDelay', 'Intercept'\n",
    "]\n",
    "assert_equal(set(X.columns), set(columns))\n",
    "assert_array_almost_equal(local.DepDelay.values, X.DepDelay.values)\n",
    "assert_array_almost_equal(X.Intercept.values, [1.0] * len(local))\n",
    "for i in [2, 3, 4, 5, 6, 7]:\n",
    "    assert_index_equal(\n",
    "        X[X[\"C(DayOfWeek)[T.{}]\".format(i)] == 1.0].index,\n",
    "        local[local.DayOfWeek == i].index\n",
    "    )\n",
    "assert_array_equal(local.ArrLate.values, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b93a84ce0b04ef9d7d1ec7025706fa0b",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To evaluate how well our regressor will perform on new, unseen data, we want to train on a subset of the data and test this new regressor on unseen test data. So, we split our data into a training sample, and a testing sample by using the `train_test_split()` method in scikit learn. Specifically, in this example, we use 75% of the data for training and 25% of the data for testing. Note that by providing an integer to the optional paramter `random_state`, the `train_test_split()` function becomes deterministic, and we get the same split every time we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b7fc330327ffb8c2d7084841759ef433",
     "grade": false,
     "grade_id": "train_test_split",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d1b208be56efde9ca79b6952af0793f8",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Fit a logistic regression model\n",
    "\n",
    "In the following code cell, \n",
    "\n",
    "- Write a function named `fit_logistic_regression_model()`.\n",
    "\n",
    "- Use the `LogisticRegression()` method in scikit learn to train a logistic regression model on the training set.\n",
    "\n",
    "- Use the model to predict `ArrLate` from the `DepDelay` and `DayOfWeek` columns of the test set.\n",
    "\n",
    "- Finally, return the predicted values as a one-dimensioanl numpy array.\n",
    "\n",
    "- Note that `fit_logistic_regression_model()` takes 4 arguments, but it is not necessary that you use all 4 arguments. You should decide which arguments are needed and which are not.\n",
    "\n",
    "When we use this function on the training and test sets that we created in the previous code cell, we get an accuracy of 88.7 %.\n",
    "\n",
    "```python\n",
    ">>> y_pred = fit_logistic_regression_model(X_train, X_test, y_train, y_test)\n",
    ">>> accuracy = accuracy_score(y_test, y_pred)\n",
    ">>> print(\"accuracy = {0:3.1f} %.\".format(100.0 * accuracy))\n",
    "```\n",
    "```\n",
    "accuracy = 88.7 %.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "72ce40538c0ac73bc096243c648fe60a",
     "grade": false,
     "grade_id": "fit_logistic_regression_model_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_logistic_regression_model(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Fits a logistic regression model and returns the predicted values of \"ArrLate\".\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    X_train: A pandas data frame. The features of the training set.\n",
    "    X_test: A pandas data frame. The features of the test set.\n",
    "    y_train: A numpy array. The labels of the training set.\n",
    "    y_test: A numpy array. The labels of the test set.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 1-D numpy array. Predicted values of \"ArrLate\".\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "664e024d02eb7e8af6f98f723aea345c",
     "grade": false,
     "grade_id": "fit_logistic_regression_model_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = fit_logistic_regression_model(X_train, X_test, y_train, y_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy = {0:3.1f} %.\".format(100.0 * accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b4a39969944dbcd13156f42f30fa74bb",
     "grade": true,
     "grade_id": "fit_logistic_regression_model_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(y_pred, np.ndarray)\n",
    "assert_equal(len(y_pred), len(X_test))\n",
    "assert_array_equal(\n",
    "    np.where(y_pred != y_test)[0],\n",
    "[  5,   6,  12,  24,  26,  31,  38,  39,  46,  53,  60,  61,  62,\n",
    "        64,  78,  83, 103, 110, 114, 128, 142, 156, 159, 167, 196, 205,\n",
    "       208, 213, 219, 229, 233, 236, 250, 251, 252, 261, 280, 297, 304,\n",
    "       312, 338, 349, 376, 384, 392, 400, 408, 412]\n",
    ")\n",
    "assert_almost_equal(accuracy, 0.8867924528301887)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
