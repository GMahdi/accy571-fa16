#Week 14: #

## Column Oriented DataStores and Spark ##

This week we start by concluding our discussion on NoSQL Databases, specifically focusing on Column oriented data stores like Cassandra. Next, we introduce Spark, a popular big data processing environment.
Spark provides a non Map-Reduce framework on top of Hadoop. Spark also
provides specific data structures, including the Resilient Distributed
Dataset (RDD) and DataFrame that simplify big data processing tasks. In
this course, we will use pySpark to perform Spark processing from within
an IPython Notebook.

### Objectives ###

#####By the end of this lesson, you should be able to:######

- Understand the basics of column-oriented
- Understand how to connect to these database from a Python program.
- Be able to insert, update, select, and delete data from these database
by using a Python program.
- Understand the basic concepts of Spark
- Understand and be able to use Spark RDDs and DataFrames 
- Be able to execute Spark tasks in a Hadoop environment


### Activities and Assignments ###

|Activities and Assignments | Time Estimate | Deadline* | 
|:------| -----|---------:|
|**[Week 14 Lesson 1: Introduction to Column Databases (NoSQL)](lesson1.md)**| 3 Hours | Monday|
|**[Week 14 Lesson 2: Introduction to Spark](lesson2.md)**| 3 Hours |Wednesday|

*Please note that unless otherwise noted, the due time is 6pm Central time!*

----------